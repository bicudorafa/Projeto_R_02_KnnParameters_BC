dados_treino_labels <- subset(dados[1], amostra == T)[,1]
str(dados_treino_labels)
dados_treino_labels <- subset(dados[1], amostra == T)[,1]
dados_teste_labels <- subset(dados[1], amostra == F)[,1]
# Criando o Modelo
modelo <- knn(train = dados_treino,
test = dados_teste,
cl = dados_treino_labels,
k = 21)
class(modelo)
head(modelo)
# Carregando o gmodels
install.packages("gmodels")
library(gmodels)
dados <- read.csv("bc_data.csv", stringsAsFactors = FALSE)
str(dados)
head(dados)
## Etapa 2 - Explorando os Dados
# Excluindo a coluna ID
# Independete do mÃ©todo de aprendizado de mÃ¡quina, colunas de identificaÃ§Ã£o sempre devem ser excluÃ­das
# variÃƒÂ¡veis de ID. Caso contrÃƒÂ¡rio, isso pode levar a resultados errados porque o ID
# Porque a feature ID serve unicamente para "prever" as observaÃ§Ãµes de referÃªncia
# Isso pode levar a overfitting ou outros problemas, por nÃ£o possuir info Ãºtil (na maioria dos casos)
dados <- dados[-1]
str(dados)
any(is.na(dados))
# Realizado o processo de Factoring em nossa variÃ¡vel resposta (por boa parte dos algorÃ­timos exigir)
dados$diagnosis <- factor(dados$diagnosis, levels = c('B', 'M'), labels = c('Benigno', 'Maligno'))
# Verificado a proporÃ§Ã£o dos meus dados alvo
round(prop.table(table(dados$diagnosis))*100, digits = 1)
# NormalizaÃ§Ã£o dos dados
# Outra caracterÃ­stica comum a muitos processos de machine learning Ã© a normalizaÃ§Ã£o dos dados
# DiferenÃ§as de escala entre os preditores podem sempre causar distorÃ§Ãµes indesejadas (ao menos, na maioria dos casos)
# funÃ§Ã£o base R para normalizaÃ§Ã£o -> scale
dados_normalizados <- scale(dados[2:31])
# Fazendo uma comparaÃ§Ã£o entre algumas features antes e apÃ³s
summary(dados[c("radius_mean", "area_mean", "smoothness_mean")])
summary(dados_normalizados[c("radius_mean", "area_mean", "smoothness_mean")])
## Etapa 3: Treinando o modelo
# Carregando os pacotes necessÃ¡rios
# install.packages("class")
# install.packages("caTools")
library(caTools)
library(class)
# Criando os dados de treino e os de teste (obs.: neste dataset em especial nÃ£o seria necessÃ¡rio por ser randomizado originalmente)
set.seed(69)
amostra <- sample.split(dados$diagnosis, SplitRatio = 0.70)
dados_treino <- as.data.frame(subset(dados_normalizados, amostra == T))
dados_teste <- as.data.frame(subset(dados_normalizados, amostra == F))
# Criando os labels para identificaÃ§Ã£o no modelo
dados_treino_labels <- subset(dados[1], amostra == T)[,1]
dados_teste_labels <- subset(dados[1], amostra == F)[,1]
# Criando o Modelo
modelo <- knn(train = dados_treino,
test = dados_teste,
cl = dados_treino_labels,
k = 21)
CrossTable(x = dados_teste_labels, y = modelo, prop.chisq = FALSE)
taxa_erro1 = mean(dados_teste_labels == modelo)
taxa_erro1
taxa_erro1 = mean(dados_teste_labels != modelo)
taxa_erro1
prev = NULL
taxa_erro = NULL
k_values = 1:20
#obs.: sempre que for realizar um loop, Ã© bom costume fazÃª-los vazios para garantir isso
suppressWarnings(
for(i in k_values){
set.seed(101)
prev = knn(train = dados_treino, test = dados_teste, cl = dados_treino_labels, k = i)
taxa_erro[i] = mean(dados$diagnosis != prev)
})
# Obtendo os valores de k e das taxas de erro
df_erro <- data.frame(taxa_erro, k.values)
df_erro
# ÃƒÂ€ medida que aumentamos k, diminuÃƒ­mos a taxa de erro do modelo
ggplot(df_erro, aes(x = k.values, y = taxa_erro)) + geom_point()+ geom_line(lty = "dotted", color = 'red')
library(ggplot2)
prev = NULL
taxa_erro = NULL
k_values = 1:20
#obs.: sempre que for realizar um loop, Ã© bom costume fazÃª-los vazios para garantir isso
suppressWarnings(
for(i in k_values){
set.seed(101)
prev = knn(train = dados_treino, test = dados_teste, cl = dados_treino_labels, k = i)
taxa_erro[i] = mean(dados$diagnosis != prev)
})
# Obtendo os valores de k e das taxas de erro
df_erro <- data.frame(taxa_erro, k_values)
df_erro
# ÃƒÂ€ medida que aumentamos k, diminuÃƒ­mos a taxa de erro do modelo
ggplot(df_erro, aes(x = k_values, y = taxa_erro)) + geom_point()+ geom_line(lty = "dotted", color = 'red')
mean(dados_teste_labels != modelo)
prev = NULL
taxa_erro = NULL
k_values = 1:25
#obs.: sempre que for realizar um loop, Ã© bom costume fazÃª-los vazios para garantir isso
suppressWarnings(
for(i in k_values){
set.seed(101)
prev = knn(train = dados_treino, test = dados_teste, cl = dados_treino_labels, k = i)
taxa_erro[i] = mean(dados$diagnosis != prev)
})
# Obtendo os valores de k e das taxas de erro
df_erro <- data.frame(taxa_erro, k_values)
df_erro
# ÃƒÂ€ medida que aumentamos k, diminuÃƒ­mos a taxa de erro do modelo
ggplot(df_erro, aes(x = k_values, y = taxa_erro)) + geom_point()+ geom_line(lty = "dotted", color = 'red')
prev = NULL
taxa_erro = NULL
k_values = 1:25
#obs.: sempre que for realizar um loop, Ã© bom costume comeÃ§Ã¡-los vazios para garantir isso
suppressWarnings(
for(i in k_values){
set.seed(101)
prev = knn(train = dados_treino,
test = dados_teste,
cl = dados_treino_labels,
k = i)
taxa_erro[i] = mean(dados_teste_labels != prev)
})
# Obtendo os valores de k e das taxas de erro
df_erro <- data.frame(taxa_erro, k_values)
df_erro
# ÃƒÂ€ medida que aumentamos k, diminuÃƒ­mos a taxa de erro do modelo
ggplot(df_erro, aes(x = k_values, y = taxa_erro)) + geom_point()+ geom_line(lty = "dotted", color = 'red')
ggplot(df_erro, aes(x = k_values, y = taxa_erro)) +
geom_point()+
geom_line(lty = "dotted", color = 'red') +
labs(title = 'Taxa de Erro em FunÃ§Ã£o dos Valores de K',
x = 'Taxa de Erro', y = 'Valores de K')
ggplot(df_erro, aes(x = k_values, y = taxa_erro)) +
geom_point()+
geom_line(lty = "dotted", color = 'red') +
labs(title = 'Taxa de Erro em FunÃ§Ã£o dos Valores de K',
x = 'Taxa de Erro', y = 'Valores de K') +
theme_classic()
ggplot(df_erro, aes(x = k_values, y = taxa_erro)) +
geom_point()+
geom_line(lty = "dotted", color = 'red') +
labs(title = 'Taxa de Erro em FunÃ§Ã£o dos Valores de K',
y = 'Taxa de Erro', x = 'Valores de K') +
theme_classic()
dados <- read.csv("bc_data.csv", stringsAsFactors = FALSE)
names(dados)
dados <- dados[-'id']
dados <- dados[-c('id')]
dados <- subset(dados, select = - id)
str(dados)
any(is.na(dados))
dados$diagnosis <- factor(dados$diagnosis, levels = c('B', 'M'), labels = c('Benigno', 'Maligno'))
# Verificado a proporÃ§Ã£o dos meus dados alvo
round(prop.table(table(dados$diagnosis))*100, digits = 1)
install.packages("class")
install.packages("caTools")
library(caTools)
library(class)
set.seed(69)
amostra <- sample.split(dados$diagnosis, SplitRatio = 0.70)
dados_treino <- as.data.frame(subset(dados_normalizados, amostra == T))
dados_teste <- as.data.frame(subset(dados_normalizados, amostra == F))
install.packages("gmodels")
modelo <- knn(train = dados_treino,
test = dados_teste,
cl = dados_treino_labels,
k = 21)
modelo
summary(modelo)
CrossTable(x = dados_teste_labels, y = modelo, prop.chisq = FALSE)
taxa_erro_inicial = mean(dados_teste_labels != modelo)
# install.packages("ggplot2")
library(gmodels)
library(ggplot2)
CrossTable(x = dados_teste_labels, y = modelo, prop.chisq = FALSE)
taxa_erro_inicial = mean(dados_teste_labels != modelo)
# Calculando funÃ§Ã£o taxa de erro em relaÃ§Ã£o ao tamanho do k
prev = NULL
taxa_erro = NULL
k_values = 1:25
#obs.: sempre que for realizar um loop, Ã© bom costume comeÃ§Ã¡-los vazios para garantir isso
suppressWarnings(
for(i in k_values){
set.seed(101)
prev = knn(train = dados_treino,
test = dados_teste,
cl = dados_treino_labels,
k = i)
taxa_erro[i] = mean(dados_teste_labels != prev)
})
df_erro <- data.frame(taxa_erro, k_values)
df_erro
# Plotando a relaÃ§Ã£o entre as duas variÃ¡veis
ggplot(df_erro, aes(x = k_values, y = taxa_erro)) +
geom_point()+
geom_line(lty = "dotted", color = 'red') +
labs(title = 'Taxa de Erro em FunÃ§Ã£o dos Valores de K',
y = 'Taxa de Erro', x = 'Valores de K') +
theme_classic()
dados <- read.csv("bc_data.csv", stringsAsFactors = FALSE)
head(dados)
names(dados)
dados_down <- read.csv(link_dados, stringsAsFactors = F)
link_dados <- 'http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data'
dados_down <- read.csv(link_dados, stringsAsFactors = F)
str(dados_down)
dados_down <- read.csv(link_dados, stringsAsFactors = F, header = F)
dados_down <- read.csv(link_dados, stringsAsFactors = F, header = names(dados))
dados_down <- read.csv(link_dados, stringsAsFactors = F, col.names = names(dados))
link_dados <- 'http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data'
# definicao dos nomes das features
names_bc = c("id", "diagnosis", "radius_mean", "texture_mean", "perimeter_mean", "area_mean", "smoothness_mean",
"compactness_mean", "concavity_mean", "points_mean", "symmetry_mean", "dimension_mean", "radius_se",
"texture_se", "perimeter_se", "area_se", "smoothness_se", "compactness_se", "concavity_se", "points_se",
"symmetry_se", "dimension_se", "radius_worst", "texture_worst", "perimeter_worst", "area_worst",
"smoothness_worst", "compactness_worst", "concavity_worst", "points_worst", "symmetry_worst","dimension_worst")
dados <- read.csv(link_dados, stringsAsFactors = F, col.names = names(dados))
str(dados)
head(dados)
## Etapa 1 - Coletando os Dados
# Origem: http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29
# Os dados do cancer da mama incluem 569 observaÃ§Ãµes de biopsias de cancer
# Cada observaÃ§Ã£o possui 32 features, sendo a 1a delas sua identificaÃ§Ã£o (ID),
# a 2a Ã© o diagnostico (diagnosis), sendo B = benigno e M = malicioso
# E as 30 features restantes sÃ£o medidas laboratoriais nucleares cuja explicacao encontra-se no link
# http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names
# link para os dados
link_dados <- 'http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data'
# definicao dos nomes das features
names_bc = c("id", "diagnosis", "radius_mean", "texture_mean", "perimeter_mean", "area_mean", "smoothness_mean",
"compactness_mean", "concavity_mean", "points_mean", "symmetry_mean", "dimension_mean", "radius_se",
"texture_se", "perimeter_se", "area_se", "smoothness_se", "compactness_se", "concavity_se", "points_se",
"symmetry_se", "dimension_se", "radius_worst", "texture_worst", "perimeter_worst", "area_worst",
"smoothness_worst", "compactness_worst", "concavity_worst", "points_worst", "symmetry_worst","dimension_worst")
dados <- read.csv(link_dados, stringsAsFactors = F, col.names = names(dados))
str(dados)
head(dados)
## Etapa 2 - Explorando os Dados
# Excluindo a coluna ID
# Independete do mÃ©todo de aprendizado de mÃ¡quina, colunas de identificaÃ§Ã£o sempre devem ser excluÃ­das
# Porque a feature ID serve unicamente para "prever" as observaÃ§Ãµes de referencia
# Isso pode levar a overfitting ou outros problemas, por nÃ£o possuir info Ãºtil (na maioria dos casos)
dados <- subset(dados, select = - id)
str(dados)
any(is.na(dados))
# Realizado o processo de Factoring em nossa variÃ¡vel resposta (por boa parte dos algorÃ­timos exigir)
dados$diagnosis <- factor(dados$diagnosis, levels = c('B', 'M'), labels = c('Benigno', 'Maligno'))
# Verificado a proporÃ§Ã£o dos meus dados alvo
round(prop.table(table(dados$diagnosis))*100, digits = 1)
# NormalizaÃ§Ã£o dos dados
# Outra caracterÃ­stica comum a muitos processos de machine learning Ã© a normalizaÃ§Ã£o dos dados
# DiferenÃ§as de escala entre os preditores podem sempre causar distorÃ§Ãµes indesejadas
# (ao menos, na maioria dos casos)
# funÃ§Ã£o base R para normalizaÃ§Ã£o -> scale
dados_normalizados <- scale(dados[2:31])
# Fazendo uma comparaÃ§Ã£o entre algumas features antes e apÃ³s
summary(dados[c("radius_mean", "area_mean", "smoothness_mean")])
summary(dados_normalizados[c("radius_mean", "area_mean", "smoothness_mean")])
## Etapa 3: Treinando o modelo
# Carregando os pacotes necessÃ¡rios
# install.packages("class")
# install.packages("caTools")
library(caTools)
library(class)
# Criando os dados de treino e os de teste (obs.: neste dataset em especial nÃ£o seria
# necessÃ¡rio por ser randomizado originalmente)
set.seed(69)
amostra <- sample.split(dados$diagnosis, SplitRatio = 0.70)
dados_treino <- as.data.frame(subset(dados_normalizados, amostra == T))
dados_teste <- as.data.frame(subset(dados_normalizados, amostra == F))
# Criando os labels para identificaÃ§Ã£o no modelo
dados_treino_labels <- subset(dados[1], amostra == T)[,1]
dados_teste_labels <- subset(dados[1], amostra == F)[,1]
# Criando o Modelo
modelo <- knn(train = dados_treino,
test = dados_teste,
cl = dados_treino_labels,
k = 21)
## Etapa 4: Avaliando e Interpretando o Modelo
# Carregando o gmodels
# install.packages("gmodels")
# install.packages("ggplot2")
library(gmodels)
library(ggplot2)
# Criando uma tabela cruzada dos dados previstos x dados atuais, ou seja, uma ConfusionMatrix e analisando taxa de erro
CrossTable(x = dados_teste_labels, y = modelo, prop.chisq = FALSE)
taxa_erro_inicial = mean(dados_teste_labels != modelo)
# Calculando funÃ§Ã£o taxa de erro em relaÃ§Ã£o ao tamanho do k
prev = NULL
taxa_erro = NULL
k_values = 1:25
#obs.: sempre que for realizar um loop, Ã© bom costume comeÃ§Ã¡-los vazios para garantir isso
suppressWarnings(
for(i in k_values){
set.seed(101)
prev = knn(train = dados_treino,
test = dados_teste,
cl = dados_treino_labels,
k = i)
taxa_erro[i] = mean(dados_teste_labels != prev)
})
df_erro <- data.frame(taxa_erro, k_values)
df_erro
# Plotando a relaÃ§Ã£o entre as duas variÃ¡veis
ggplot(df_erro, aes(x = k_values, y = taxa_erro)) +
geom_point()+
geom_line(lty = "dotted", color = 'red') +
labs(title = 'Taxa de Erro em FunÃ§Ã£o dos Valores de K',
y = 'Taxa de Erro', x = 'Valores de K') +
theme_classic()
## Etapa 1 - Coletando os Dados
# Origem: http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29
# Os dados do cancer da mama incluem 569 observaÃ§Ãµes de biopsias de cancer
# Cada observaÃ§Ã£o possui 32 features, sendo a 1a delas sua identificaÃ§Ã£o (ID),
# a 2a Ã© o diagnostico (diagnosis), sendo B = benigno e M = malicioso
# E as 30 features restantes sÃ£o medidas laboratoriais nucleares cuja explicacao encontra-se no link
# http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names
# link para os dados
link_dados <- 'http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data'
# definicao dos nomes das features
names_bc = c("id", "diagnosis", "radius_mean", "texture_mean", "perimeter_mean", "area_mean", "smoothness_mean",
"compactness_mean", "concavity_mean", "points_mean", "symmetry_mean", "dimension_mean", "radius_se",
"texture_se", "perimeter_se", "area_se", "smoothness_se", "compactness_se", "concavity_se", "points_se",
"symmetry_se", "dimension_se", "radius_worst", "texture_worst", "perimeter_worst", "area_worst",
"smoothness_worst", "compactness_worst", "concavity_worst", "points_worst", "symmetry_worst","dimension_worst")
dados <- read.csv(link_dados, stringsAsFactors = F, col.names = names(dados))
str(dados)
head(dados)
## Etapa 2 - Explorando os Dados
# Excluindo a coluna ID
# Independete do mÃ©todo de aprendizado de mÃ¡quina, colunas de identificaÃ§Ã£o sempre devem ser excluÃ­das
# Porque a feature ID serve unicamente para "prever" as observaÃ§Ãµes de referencia
# Isso pode levar a overfitting ou outros problemas, por nÃ£o possuir info Ãºtil (na maioria dos casos)
dados <- subset(dados, select = - id)
str(dados)
any(is.na(dados))
# Realizado o processo de Factoring em nossa variÃ¡vel resposta (por boa parte dos algorÃ­timos exigir)
dados$diagnosis <- factor(dados$diagnosis, levels = c('B', 'M'), labels = c('Benigno', 'Maligno'))
# Verificado a proporÃ§Ã£o dos meus dados alvo
round(prop.table(table(dados$diagnosis))*100, digits = 1)
# NormalizaÃ§Ã£o dos dados
# Outra caracterÃ­stica comum a muitos processos de machine learning Ã© a normalizaÃ§Ã£o dos dados
# DiferenÃ§as de escala entre os preditores podem sempre causar distorÃ§Ãµes indesejadas
# (ao menos, na maioria dos casos)
# funÃ§Ã£o base R para normalizaÃ§Ã£o -> scale
dados_normalizados <- scale(dados[2:31])
# Fazendo uma comparaÃ§Ã£o entre algumas features antes e apÃ³s
summary(dados[c("radius_mean", "area_mean", "smoothness_mean")])
summary(dados_normalizados[c("radius_mean", "area_mean", "smoothness_mean")])
## Etapa 3: Treinando o modelo
# Carregando os pacotes necessÃ¡rios
# install.packages("class")
# install.packages("caTools")
library(caTools)
library(class)
# Criando os dados de treino e os de teste (obs.: neste dataset em especial nÃ£o seria
# necessÃ¡rio por ser randomizado originalmente)
set.seed(69)
amostra <- sample.split(dados$diagnosis, SplitRatio = 0.70)
dados_treino <- as.data.frame(subset(dados_normalizados, amostra == T))
dados_teste <- as.data.frame(subset(dados_normalizados, amostra == F))
# Criando os labels para identificaÃ§Ã£o no modelo
dados_treino_labels <- subset(dados[1], amostra == T)[,1]
dados_teste_labels <- subset(dados[1], amostra == F)[,1]
# Criando o Modelo
modelo <- knn(train = dados_treino,
test = dados_teste,
cl = dados_treino_labels,
k = 21)
## Etapa 4: Avaliando e Interpretando o Modelo
# Carregando o gmodels
# install.packages("gmodels")
# install.packages("ggplot2")
library(gmodels)
library(ggplot2)
# Criando uma tabela cruzada dos dados previstos x dados atuais, ou seja, uma ConfusionMatrix e analisando taxa de erro
CrossTable(x = dados_teste_labels, y = modelo, prop.chisq = FALSE)
taxa_erro_inicial = mean(dados_teste_labels != modelo)
# Calculando funÃ§Ã£o taxa de erro em relaÃ§Ã£o ao tamanho do k
prev = NULL
taxa_erro = NULL
k_values = 1:25
#obs.: sempre que for realizar um loop, Ã© bom costume comeÃ§Ã¡-los vazios para garantir isso
suppressWarnings(
for(i in k_values){
set.seed(101)
prev = knn(train = dados_treino,
test = dados_teste,
cl = dados_treino_labels,
k = i)
taxa_erro[i] = mean(dados_teste_labels != prev)
})
df_erro <- data.frame(taxa_erro, k_values)
df_erro
# Plotando a relaÃ§Ã£o entre as duas variÃ¡veis
ggplot(df_erro, aes(x = k_values, y = taxa_erro)) +
geom_point()+
geom_line(lty = "dotted", color = 'red') +
labs(title = 'Taxa de Erro em FunÃ§Ã£o dos Valores de K',
y = 'Taxa de Erro', x = 'Valores de K') +
theme_classic()
modelo <- knn(train = dados_treino,
test = dados_teste,
cl = dados_treino_labels)
(107+59)/(107+59+4)
install.packages(stringi)
install.packages('stringi')
knitr::opts_chunk$set(echo = TRUE)
# Coletando dados
# link para os dados
link_dados <- 'http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data'
# definicao dos nomes das features
names_bc = c("id", "diagnosis", "radius_mean", "texture_mean", "perimeter_mean", "area_mean", "smoothness_mean",
"compactness_mean", "concavity_mean", "points_mean", "symmetry_mean", "dimension_mean", "radius_se",
"texture_se", "perimeter_se", "area_se", "smoothness_se", "compactness_se", "concavity_se", "points_se",
"symmetry_se", "dimension_se", "radius_worst", "texture_worst", "perimeter_worst", "area_worst",
"smoothness_worst", "compactness_worst", "concavity_worst", "points_worst", "symmetry_worst","dimension_worst")
dados <- read.csv(link_dados, stringsAsFactors = F, col.names = names(dados))
str(dados)
View(dados_down)
# link para os dados
link_dados <- 'http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data'
# definicao dos nomes das features
names_bc = c("id", "diagnosis", "radius_mean", "texture_mean", "perimeter_mean", "area_mean", "smoothness_mean",
"compactness_mean", "concavity_mean", "points_mean", "symmetry_mean", "dimension_mean", "radius_se",
"texture_se", "perimeter_se", "area_se", "smoothness_se", "compactness_se", "concavity_se", "points_se",
"symmetry_se", "dimension_se", "radius_worst", "texture_worst", "perimeter_worst", "area_worst",
"smoothness_worst", "compactness_worst", "concavity_worst", "points_worst", "symmetry_worst","dimension_worst")
dados <- read.csv(link_dados, stringsAsFactors = F, col.names = names(dados))
str(dados)
# link para os dados
link_dados <- 'http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data'
# definicao dos nomes das features
names_bc = c("id", "diagnosis", "radius_mean", "texture_mean", "perimeter_mean", "area_mean", "smoothness_mean",
"compactness_mean", "concavity_mean", "points_mean", "symmetry_mean", "dimension_mean", "radius_se",
"texture_se", "perimeter_se", "area_se", "smoothness_se", "compactness_se", "concavity_se", "points_se",
"symmetry_se", "dimension_se", "radius_worst", "texture_worst", "perimeter_worst", "area_worst",
"smoothness_worst", "compactness_worst", "concavity_worst", "points_worst", "symmetry_worst","dimension_worst")
dados <- read.csv(link_dados, stringsAsFactors = F, col.names = names_bc)
str(dados)
head(dados)
# Coletando dados
# link para os dados
link_dados <- 'http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data'
# definicao dos nomes das features
names_bc = c("id", "diagnosis", "radius_mean", "texture_mean", "perimeter_mean", "area_mean", "smoothness_mean",
"compactness_mean", "concavity_mean", "points_mean", "symmetry_mean", "dimension_mean", "radius_se",
"texture_se", "perimeter_se", "area_se", "smoothness_se", "compactness_se", "concavity_se", "points_se",
"symmetry_se", "dimension_se", "radius_worst", "texture_worst", "perimeter_worst", "area_worst",
"smoothness_worst", "compactness_worst", "concavity_worst", "points_worst", "symmetry_worst","dimension_worst")
dados <- read.csv(link_dados, stringsAsFactors = F, col.names = names_bc)
str(dados)
install.packages('tinytex')
## Etapa 2 - Explorando os Dados
# Excluindo a coluna ID
dados <- subset(dados, select = - id)
# Realizado o processo de Factoring em nossa variÃ¡vel resposta (por boa parte dos algorÃ­timos exigir)
dados$diagnosis <- factor(dados$diagnosis, levels = c('B', 'M'), labels = c('Benigno', 'Maligno'))
# Verificado a proporÃ§Ã£o dos meus dados alvo
round(prop.table(table(dados$diagnosis))*100, digits = 1)
# NormalizaÃ§Ã£o dos dados
summary(dados)
# funÃ§Ã£o base R para normalizaÃ§Ã£o -> scale
dados_normalizados <- scale(dados[2:31])
# Fazendo uma comparaÃ§Ã£o entre algumas features antes e apÃ³s
summary(dados[c("radius_mean", "area_mean", "smoothness_mean")])
summary(dados_normalizados[c("radius_mean", "area_mean", "smoothness_mean")])
str(dados_normalizados)
dados_normalizados <- as.data.frame(scale(dados[2:31]))
summary(dados[c("radius_mean", "area_mean", "smoothness_mean")])
summary(dados_normalizados[c("radius_mean", "area_mean", "smoothness_mean")])
dados_treino_labels <- as.data.frame(subset(dados[1], amostra == T))
dados_teste_labels <- as.data.frame(subset(dados[1], amostra == F))
# Criando o Modelo
modelo <- knn(train = dados_treino,
test = dados_teste,
cl = dados_treino_labels)
# necessÃ¡rio por ser randomizado originalmente)
set.seed(69)
amostra <- sample.split(dados$diagnosis, SplitRatio = 0.70)
dados_treino <- as.data.frame(subset(dados_normalizados, amostra == T))
dados_teste <- as.data.frame(subset(dados_normalizados, amostra == F))
# Criando os labels para identificaÃ§Ã£o no modelo
dados_treino_labels <- as.data.frame(subset(dados[1], amostra == T))
dados_teste_labels <- as.data.frame(subset(dados[1], amostra == F))
# Criando o Modelo
modelo <- knn(train = dados_treino,
test = dados_teste,
cl = dados_treino_labels)
set.seed(69)
amostra <- sample.split(dados$diagnosis, SplitRatio = 0.70)
dados_treino <- as.data.frame(subset(dados_normalizados, amostra == T))
dados_teste <- as.data.frame(subset(dados_normalizados, amostra == F))
# Criando os labels para identificaÃ§Ã£o no modelo
dados_treino_labels <- subset(dados[1], amostra == T)[,1]
dados_teste_labels <- subset(dados[1], amostra == F)[,1]
# Criando o Modelo
modelo <- knn(train = dados_treino,
test = dados_teste,
cl = dados_treino_labels)
# necessÃ¡rio por ser randomizado originalmente)
set.seed(69)
amostra <- sample.split(dados$diagnosis, SplitRatio = 0.70)
dados_treino <- as.data.frame(subset(dados_normalizados, amostra == T))
dados_teste <- as.data.frame(subset(dados_normalizados, amostra == F))
# Criando os labels para identificaÃ§Ã£o no modelo
dados_treino_labels <- subset(dados[1], amostra == T)[,1]
dados_teste_labels <- subset(dados[1], amostra == F)[,1]
# Criando o Modelo
modelo <- knn(train = dados_treino,
test = dados_teste,
cl = dados_treino_labels)
